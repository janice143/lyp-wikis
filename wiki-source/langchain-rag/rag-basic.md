# **ç¬¬å››ç« ï¼šæ­å»ºåŸºç¡€ RAG åº”ç”¨**

æœ¬ç« å°†å¸¦ä½  **ä»é›¶æ­å»ºä¸€ä¸ªåŸºç¡€çš„ RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰ç³»ç»Ÿ**ï¼ŒåŒ…æ‹¬ï¼š
âœ… **ç¯å¢ƒæ­å»º**ï¼ˆPython ä¾èµ–ã€API Key é…ç½®ï¼‰  
âœ… **æ–‡æ¡£æ£€ç´¢**ï¼ˆè¯»å–æ–‡æœ¬ã€å­˜å…¥å‘é‡æ•°æ®åº“ï¼‰  
âœ… **ç»“åˆ LLM è¿›è¡Œé—®ç­”**ï¼ˆRetrievalQAï¼‰  
âœ… **è¿è¡Œä¸æµ‹è¯•**ï¼ˆç»ˆç«¯äº¤äº’ & Streamlit Web UIï¼‰

---

## **1. ç¯å¢ƒæ­å»º**

RAG éœ€è¦é›†æˆå¤šä¸ªå·¥å…·ï¼ŒåŒ…æ‹¬ **å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ã€å‘é‡æ•°æ®åº“ï¼ˆVector Storeï¼‰ã€æ–‡æ¡£å¤„ç†ï¼ˆPDF, Web Scraperï¼‰ç­‰**ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ **LangChain** æ¡†æ¶ï¼Œå®ƒå¯ä»¥è½»æ¾æ•´åˆè¿™äº›ç»„ä»¶ã€‚

### **1.1 å®‰è£… Python ä¾èµ–**

ä½¿ç”¨ `pip` å®‰è£… RAG ç›¸å…³çš„ä¾èµ–ï¼š

```bash
pip install langchain openai faiss-cpu chromadb tiktoken beautifulsoup4 pdfplumber streamlit
```

#### **ä¾èµ–ä»‹ç»**

- `langchain`ï¼šRAG ç»„ä»¶æ¡†æ¶
- `openai`ï¼šè°ƒç”¨ GPT-4 / GPT-3.5
- `faiss-cpu`ï¼šæœ¬åœ°å‘é‡æ•°æ®åº“
- `chromadb`ï¼šè½»é‡çº§å‘é‡æ•°æ®åº“
- `pdfplumber`ï¼šå¤„ç† PDF
- `beautifulsoup4`ï¼šè§£æç½‘é¡µ HTML
- `streamlit`ï¼šæ„å»º Web UI

---

### **1.2 é…ç½® API Key**

RAG éœ€è¦è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆå¦‚ OpenAIã€Hugging Faceï¼‰ï¼Œéœ€è¦è®¾ç½® API Keyã€‚

#### **è®¾ç½® OpenAI API Key**

```bash
export OPENAI_API_KEY="your-api-key"
```

æˆ–åœ¨ Python ä»£ç ä¸­ï¼š

```python
import os
os.environ["OPENAI_API_KEY"] = "your-api-key"
```

#### **å¯é€‰ï¼šHugging Face Embeddings**

```bash
export HUGGINGFACE_API_KEY="your-hf-api-key"
```

---

## **2. å®ç°æ–‡æ¡£æ£€ç´¢**

### **2.1 è¯»å–æ–‡æœ¬ã€PDFã€ç½‘é¡µæ•°æ®**

RAG éœ€è¦ä»å¤šä¸ªæ¥æºè·å–æ•°æ®ï¼Œæˆ‘ä»¬å…ˆå®ç° **ä»æ–‡æœ¬ã€PDF å’Œç½‘é¡µæå–æ•°æ®**ã€‚

#### **2.1.1 è¯»å–æ–‡æœ¬æ–‡ä»¶**

```python
def read_text_file(filepath):
    with open(filepath, "r", encoding="utf-8") as file:
        return file.read()
```

#### **2.1.2 è§£æ PDF**

```python
import pdfplumber

def extract_text_from_pdf(pdf_path):
    text = ""
    with pdfplumber.open(pdf_path) as pdf:
        for page in pdf.pages:
            text += page.extract_text() + "\n"
    return text
```

#### **2.1.3 çˆ¬å–ç½‘é¡µå†…å®¹**

```python
import requests
from bs4 import BeautifulSoup

def scrape_webpage(url):
    response = requests.get(url)
    soup = BeautifulSoup(response.text, "html.parser")
    return soup.get_text()
```

---

### **2.2 å¤„ç†æ–‡æœ¬å¹¶å­˜å…¥å‘é‡æ•°æ®åº“**

ä¸ºäº†æ”¯æŒé«˜æ•ˆæ£€ç´¢ï¼Œæˆ‘ä»¬éœ€è¦å°†æ•°æ®è½¬æ¢ä¸ºå‘é‡ï¼Œå¹¶å­˜å…¥å‘é‡æ•°æ®åº“ï¼ˆFAISS / ChromaDBï¼‰ã€‚

#### **2.2.1 æ–‡æœ¬åˆ‡åˆ†**

```python
from langchain.text_splitter import RecursiveCharacterTextSplitter

def split_text(text, chunk_size=512, chunk_overlap=50):
    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)
    return splitter.split_text(text)
```

#### **2.2.2 ç”Ÿæˆæ–‡æœ¬å‘é‡**

```python
from langchain.embeddings.openai import OpenAIEmbeddings

embeddings = OpenAIEmbeddings()
vector = embeddings.embed_query("What is RAG?")
```

#### **2.2.3 å­˜å‚¨åˆ° FAISS**

```python
from langchain.vectorstores import FAISS

def store_in_faiss(texts):
    embeddings = OpenAIEmbeddings()
    vectorstore = FAISS.from_texts(texts, embedding=embeddings)
    return vectorstore

vectorstore = store_in_faiss(["RAG is a framework that integrates retrieval and generation."])
```

---

## **3. ç»“åˆ LLM è¿›è¡Œé—®ç­”**

### **3.1 åŸºç¡€ RetrievalQA ç¤ºä¾‹**

ç°åœ¨æˆ‘ä»¬å°† `FAISS` å‘é‡æ•°æ®åº“ä¸ GPT-4 ç»“åˆï¼Œæ„å»º **RAG é—®ç­”ç³»ç»Ÿ**ã€‚

```python
from langchain.chains import RetrievalQA
from langchain.chat_models import ChatOpenAI

llm = ChatOpenAI(model_name="gpt-4")

retriever = vectorstore.as_retriever()
qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)

query = "What is RAG?"
response = qa_chain.run(query)
print(response)
```

---

### **3.2 è®¾å®š Prompt ç»“æ„ä¼˜åŒ–ç”Ÿæˆ**

Prompt è®¾è®¡ä¼šå½±å“ç”Ÿæˆè´¨é‡ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ LangChain çš„ `PromptTemplate` è¿›è¡Œä¼˜åŒ–ã€‚

```python
from langchain.prompts import PromptTemplate

prompt = PromptTemplate(
    input_variables=["context", "question"],
    template="Based on the following context: {context}, answer the question: {question}"
)
```

ç„¶åå°† Prompt ç»“åˆ RetrievalQAï¼š

```python
qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever, prompt=prompt)
```

---

## **4. è¿è¡Œä¸æµ‹è¯•**

### **4.1 ç»ˆç«¯äº¤äº’å¼é—®ç­”**

æˆ‘ä»¬å¯ä»¥åˆ›å»ºä¸€ä¸ª **äº¤äº’å¼ CLI RAG æœºå™¨äºº**ã€‚

```python
def interactive_qa():
    print("RAG Bot: Ask me anything! (type 'exit' to quit)")
    while True:
        query = input("You: ")
        if query.lower() == "exit":
            break
        response = qa_chain.run(query)
        print(f"RAG Bot: {response}")

interactive_qa()
```

---

### **4.2 Streamlit å¯è§†åŒ– Web UI**

æˆ‘ä»¬å¯ä»¥ç”¨ **Streamlit** æ„å»ºä¸€ä¸ª Web ç•Œé¢ï¼Œå±•ç¤º RAG ç»“æœã€‚

#### **å®‰è£… Streamlit**

```bash
pip install streamlit
```

#### **åˆ›å»º `app.py`**

```python
import streamlit as st

st.title("RAG æ–‡æ¡£é—®ç­”ç³»ç»Ÿ")

query = st.text_input("è¯·è¾“å…¥ä½ çš„é—®é¢˜:")
if st.button("æœç´¢"):
    response = qa_chain.run(query)
    st.write(response)
```

#### **è¿è¡Œ Web UI**

```bash
streamlit run app.py
```

ç„¶åè®¿é—® `http://localhost:8501`ï¼Œå³å¯çœ‹åˆ°ä¸€ä¸ªç®€æ˜“çš„ RAG UIã€‚

---

## **æ€»ç»“**

æœ¬ç« å®ç°äº†ä¸€ä¸ªå®Œæ•´çš„ **åŸºç¡€ RAG ç³»ç»Ÿ**ï¼ŒåŒ…æ‹¬ï¼š
âœ… **ç¯å¢ƒæ­å»º**ï¼ˆå®‰è£…ä¾èµ– & é…ç½® API Keyï¼‰  
âœ… **æ–‡æ¡£æ£€ç´¢**ï¼ˆæ–‡æœ¬ã€PDFã€ç½‘é¡µï¼‰  
âœ… **å‘é‡æ•°æ®åº“å­˜å‚¨**ï¼ˆFAISS, OpenAI Embeddingsï¼‰  
âœ… **ç»“åˆ LLM ç”Ÿæˆç­”æ¡ˆ**ï¼ˆGPT-4, LangChain RetrievalQAï¼‰  
âœ… **è¿è¡Œæµ‹è¯•**ï¼ˆCLI äº¤äº’ & Streamlit Web UIï¼‰  

åœ¨ä¸‹ä¸€ç« èŠ‚ï¼Œæˆ‘ä»¬å°†**æ·±å…¥ä¼˜åŒ– RAG ç³»ç»Ÿ**ï¼Œæé«˜å¬å›ç²¾åº¦ã€å¢å¼º Prompt è®¾è®¡ï¼Œå¹¶æ¢ç´¢æ··åˆæ£€ç´¢ï¼ˆHybrid Searchï¼‰ç­‰é«˜çº§æŠ€æœ¯ï¼ ğŸš€
